#!/usr/bin/env python3
"""
üîÑ MCP Client Router
Frontend ‚Üí MCP Host ‚Üí Gemini AI ‚Üí MCP Server ‚Üí Database
"""

from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel
from typing import Optional, Dict, Any
import google.generativeai as genai
from google.generativeai.types import FunctionDeclaration
import requests
import os
from datetime import datetime
import time
import logging
import json

from app.database.connection import get_db

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Router setup
router = APIRouter()

# Request/Response Models
class MCPRequest(BaseModel):
    user_id: str

class MCPResponse(BaseModel):
    success: bool
    suggestion_text: Optional[str] = None
    suggestion_id: Optional[str] = None
    user_score: Optional[float] = None
    tree_level: Optional[int] = None
    mcp_flow_status: str
    error: Optional[str] = None

# MCP Configuration
MCP_BASE_URL = "http://localhost:8004/api/v1/mcp"
GEMINI_API_KEY = "AIzaSyArjeMqTbWoFO8NVIFBOTlcQqE4LsTDbqk"

# Gemini AI Function Definitions (DOƒûRU FORMAT)
def create_mcp_functions():
    """Gemini AI i√ßin doƒüru formatta function definitions olu≈ütur"""
    return [
        FunctionDeclaration(
            name="get_user_financial_data",
            description="Kullanƒ±cƒ±nƒ±n tam finansal verilerini al (skor, gelir, gider, kategori daƒüƒ±lƒ±mƒ±)",
            parameters={
                "type": "OBJECT",
                "properties": {
                    "user_id": {
                        "type": "STRING", 
                        "description": "Kullanƒ±cƒ±nƒ±n UUID'si"
                    }
                },
                "required": ["user_id"]
            }
        ),
        FunctionDeclaration(
            name="get_user_score",
            description="Kullanƒ±cƒ±nƒ±n mevcut finansal skorunu ve aƒüa√ß seviyesini al",
            parameters={
                "type": "OBJECT",
                "properties": {
                    "user_id": {
                        "type": "STRING", 
                        "description": "Kullanƒ±cƒ±nƒ±n UUID'si"
                    }
                },
                "required": ["user_id"]
            }
        ),
        FunctionDeclaration(
            name="get_recent_transactions", 
            description="Kullanƒ±cƒ±nƒ±n son i≈ülemlerini ve harcama trendlerini al",
            parameters={
                "type": "OBJECT",
                "properties": {
                    "user_id": {
                        "type": "STRING", 
                        "description": "Kullanƒ±cƒ±nƒ±n UUID'si"
                    },
                    "days": {
                        "type": "INTEGER",
                        "description": "Ka√ß g√ºnl√ºk ge√ßmi≈üe bakƒ±lacak"
                    }
                },
                "required": ["user_id"]
            }
        ),
        FunctionDeclaration(
            name="get_spending_analysis",
            description="Detaylƒ± harcama analizi ve kategori y√ºzdeleri", 
            parameters={
                "type": "OBJECT",
                "properties": {
                    "user_id": {
                        "type": "STRING",
                        "description": "Kullanƒ±cƒ±nƒ±n UUID'si"
                    }
                },
                "required": ["user_id"]
            }
        ),
        FunctionDeclaration(
            name="save_ai_suggestion",
            description="AI tarafƒ±ndan √ºretilen finansal √∂neriyi database'e kaydet",
            parameters={
                "type": "OBJECT", 
                "properties": {
                    "user_id": {
                        "type": "STRING",
                        "description": "Kullanƒ±cƒ±nƒ±n UUID'si"
                    },
                    "suggestion_text": {
                        "type": "STRING",
                        "description": "AI'nƒ±n √ºrettiƒüi √∂neri metni"
                    },
                    "user_score_at_time": {
                        "type": "NUMBER",
                        "description": "√ñneri anƒ±ndaki kullanƒ±cƒ± skoru"
                    }
                },
                "required": ["user_id", "suggestion_text"]
            }
        )
    ]

# MCP Functions instance
MCP_FUNCTIONS = create_mcp_functions()

class MCPClient:
    """MCP Protocol Client - Gemini AI ile MCP Server arasƒ±nda k√∂pr√º"""
    
    def __init__(self):
        # Gemini AI Configuration
        genai.configure(api_key=GEMINI_API_KEY)
        self.model = genai.GenerativeModel(
            'gemini-1.5-flash',  # Stable model - proven to work
            tools=MCP_FUNCTIONS
        )
        
        # System Prompt for FinTree
        self.system_prompt = """
        üå≥ FinTree Finansal Danƒ±≈üman Asistanƒ±sƒ±n!
        
        MCP PROTOCOL: 
        PHASE 1: Hangi verilere ihtiyacƒ±n var? MCP tool'larƒ± √ßaƒüƒ±r!
        PHASE 2: Verileri topla ve analiz et
        PHASE 3: Anlamlƒ± finansal √∂neri √ºret
        
        AVAILABLE MCP TOOLS:
        1. get_user_financial_data - Tam finansal durum (skor, gelir, gider, kategori daƒüƒ±lƒ±mƒ±)
        2. get_user_score - Sadece skor ve aƒüa√ß seviyesi  
        3. get_recent_transactions - Son harcamalar ve trendler
        4. get_spending_analysis - Detaylƒ± harcama analizi ve y√ºzdeler
        
        STRATEGY:
        - ƒ∞LK √∂nce get_user_financial_data veya get_user_score √ßaƒüƒ±r
        - Sonra get_recent_transactions veya get_spending_analysis √ßaƒüƒ±r
        - Verileri analiz edip DETAYLI √∂neri √ºret
        
        √ñNERƒ∞ KRƒ∞TERLERƒ∞:
        üìä Skor analizi (0-100 arasƒ±)
        üå≥ Aƒüa√ß seviyesi motivasyonu (1-10 seviye)
        üí∞ Kategorilere √∂zel tavsiyeler (food, transport, bills, entertainment, health, clothing)
        üìà Trend analizi (y√ºkseli≈ü/d√º≈ü√º≈ü)
        üéØ Kƒ±sa/orta/uzun vadeli hedefler
        üí° Actionable, spesifik adƒ±mlar
        
        KONU≈ûMA STƒ∞Lƒ∞:
        - T√ºrk√ße ve samimi
        - Aƒüa√ß metaforlarƒ± kullan üå≥üåøüå±üçÉ
        - Motivasyonel ama ger√ßek√ßi
        - Sayƒ±sal verilerle destekle
        - Emoji kullan ama abartma
        """

    async def call_mcp_tool(self, tool_name: str, **kwargs) -> Dict[str, Any]:
        """MCP Server'a tool √ßaƒürƒ±sƒ± yap"""
        try:
            if tool_name == "save_ai_suggestion":
                payload = {
                    "user_id": kwargs.get("user_id"),
                    "suggestion_text": kwargs.get("suggestion_text"),
                    "user_score_at_time": kwargs.get("user_score_at_time")
                }
                url = f"{MCP_BASE_URL}/save_ai_suggestion"
            else:
                payload = {
                    "user_id": kwargs.get("user_id"),
                    "parameters": {k: v for k, v in kwargs.items() if k != "user_id"}
                }
                url = f"{MCP_BASE_URL}/{tool_name}"
            
            logger.info(f"üîß MCP Tool Call: {tool_name} ‚Üí {url}")
            logger.debug(f"üì§ Payload: {payload}")
            
            response = requests.post(url, json=payload, timeout=15)
            
            if response.status_code == 200:
                result = response.json()
                success = result.get('success', False)
                logger.info(f"‚úÖ MCP Tool Response: {tool_name} ‚Üí {success}")
                if not success:
                    logger.warning(f"‚ö†Ô∏è Tool failed: {result.get('error', 'Unknown')}")
                return result
            else:
                logger.error(f"‚ùå MCP Tool HTTP Error: {tool_name} ‚Üí {response.status_code}")
                return {"success": False, "error": f"HTTP {response.status_code}"}
                
        except Exception as e:
            logger.error(f"‚ùå MCP Tool Exception: {tool_name} ‚Üí {e}")
            return {"success": False, "error": str(e)}

    async def process_mcp_request(self, user_id: str) -> Dict[str, Any]:
        """
        MCP Protocol Ana Akƒ±≈üƒ± - FIXED VERSION
        AI √ßalƒ±≈ümazsa HATA d√∂ner, fake response YOK!
        """
        logger.info(f"üöÄ STEP 1: MCP Flow Started for User: {user_id}")
        
        try:
            # Otomatik prompt olu≈ütur
            auto_query = "G√ºnl√ºk finansal durumumu analiz et ve ki≈üiselle≈ütirilmi≈ü √∂neriler ver."
            full_message = f"{self.system_prompt}\n\nKullanƒ±cƒ± ID: {user_id}\nƒ∞stek: {auto_query}"
            
            logger.info(f"üìù STEP 2: Auto Query Generated: {auto_query}")
            
            # STEP 3: Veri toplama (AI olmadan)
            logger.info("üîß STEP 3: Collecting user data from MCP tools...")
            
            collected_data = {}
            tools_used = []
            
            # Akƒ±llƒ± veri toplama - Son 30 g√ºn odaklƒ±
            data_collection_tools = [
                ("get_user_score", {}),  # Mevcut skor
                ("get_recent_transactions", {"days": 30}),  # Son 1 ay i≈ülemler
                ("get_spending_analysis", {"days": 30})  # Son 1 ay analiz
            ]
            
            for tool_name, params in data_collection_tools:
                try:
                    logger.info(f"üîß Calling {tool_name}...")
                    result = await self.call_mcp_tool(tool_name, user_id=user_id, **params)
                    
                    if result.get('success'):
                        collected_data[tool_name] = result.get('data', {})
                        tools_used.append(tool_name)
                        logger.info(f"‚úÖ {tool_name}: SUCCESS")
                    else:
                        logger.warning(f"‚ö†Ô∏è {tool_name}: FAILED - {result.get('error', 'Unknown')}")
                        
                except Exception as e:
                    logger.error(f"‚ùå {tool_name}: ERROR - {e}")
            
            logger.info(f"üìä STEP 4: Data collection complete. Tools used: {tools_used}")
            
            if not collected_data:
                logger.error("‚ùå STEP 4: No data collected from any tool!")
                return {
                    "success": False,
                    "error": "Veri toplama ba≈üarƒ±sƒ±z. Database baƒülantƒ±sƒ± kontrol edin.",
                    "mcp_flow_status": "data_collection_failed"
                }
            
            # STEP 5: AI'ya veri ve prompt g√∂nder (SINGLED REQUEST)
            logger.info("ü§ñ STEP 5: Sending data to Gemini AI...")
            
            # MOBƒ∞L BANKACILIK UYGULAMASI PROMPT
            enhanced_prompt = f"""
            Sen FinTree mobil bankacƒ±lƒ±k uygulamasƒ±nƒ±n AI asistanƒ±sƒ±n. üì±üå≥
            
            Kullanƒ±cƒ± uygulamayƒ± a√ßtƒ±ƒüƒ±nda g√∂receƒüi G√úNL√úK √ñNERƒ∞ yazƒ±sƒ± hazƒ±rla.
            
            === VERƒ∞ ANALƒ∞Zƒ∞ (Son 30 g√ºn odaklƒ±) ===
            {json.dumps(collected_data, indent=2, ensure_ascii=False)}
            
            === YAZIM KURALLARI ===
            ‚úÖ Doƒürudan kullanƒ±cƒ±ya hitap et ("Sen", "Siz")
            ‚úÖ FinTree uygulamasƒ±ndan bahset
            ‚úÖ Kƒ±sa ve √∂z (20-30 kelime ideal)
            ‚úÖ Mobil ekranda rahat okunabilir
            ‚úÖ Motivasyonel ve pozitif ton
            ‚úÖ Spesifik sayƒ±sal √∂neriler ver
            ‚úÖ Eylem odaklƒ± tavsiyelerde bulun
            
            === √áIKTI FORMATI ===
            Sadece √∂neri metnini yaz. Ba≈ülƒ±k, a√ßƒ±klama vs yok.
            √ñrnek: "Bu ay kahve harcaman %15 arttƒ±! ‚òï G√ºnde 2 kahve yerine 1 i√ßersen aylƒ±k 180‚Ç∫ tasarruf edebilirsin. üí∞"
            
            === SON 30 G√úN√úN √ñZETƒ∞ VER ===
            Kullanƒ±cƒ±nƒ±n ger√ßek verilerine g√∂re spesifik, ki≈üisel ve actionable √∂neri √ºret! üéØ
            """
            
            try:
                logger.info("‚è≥ STEP 6: Rate limiting...")
                time.sleep(2)
                
                # TEK REQUEST - Function calling YOK
                logger.info("ü§ñ STEP 7: Calling Gemini AI (single request)...")
                ai_response = self.model.generate_content(enhanced_prompt)
                
                if ai_response and ai_response.text:
                    suggestion_text = ai_response.text.strip()
                    logger.info(f"‚úÖ STEP 7: AI Response received ({len(suggestion_text)} chars)")
                    logger.info(f"üìù Preview: {suggestion_text[:100]}...")
                else:
                    logger.error("‚ùå STEP 7: AI returned empty response")
                    return {
                        "success": False,
                        "error": "AI bo≈ü response d√∂nd√º",
                        "mcp_flow_status": "ai_empty_response"
                    }
                
            except Exception as ai_error:
                logger.error(f"‚ùå STEP 7: Gemini AI Error: {ai_error}")
                
                # Quota check
                if "429" in str(ai_error) or "quota" in str(ai_error).lower():
                    return {
                        "success": False,
                        "error": "Gemini API quota a≈üƒ±ldƒ±",
                        "mcp_flow_status": "quota_exceeded"
                    }
                else:
                    return {
                        "success": False,
                        "error": f"AI hatasƒ±: {str(ai_error)}",
                        "mcp_flow_status": "ai_error"
                    }
            
            # STEP 8: √ñneriyi database'e kaydet
            logger.info("üíæ STEP 8: Saving suggestion to database...")
            
            user_score = 0
            if 'get_user_score' in collected_data:
                user_score = collected_data['get_user_score'].get('score', 0)
            
            try:
                save_result = await self.call_mcp_tool(
                    "save_ai_suggestion",
                    user_id=user_id,
                    suggestion_text=suggestion_text[:1000],
                    user_score_at_time=user_score
                )
                
                save_success = save_result.get('success', False)
                logger.info(f"üíæ STEP 8: Save result: {save_success}")
                
            except Exception as save_error:
                logger.error(f"‚ùå STEP 8: Save error: {save_error}")
                save_success = False
            
            # STEP 9: Final response
            logger.info("üéâ STEP 9: MCP Flow completed successfully!")
            
            return {
                "success": True,
                "suggestion_text": suggestion_text,
                "user_score": user_score,
                "tree_level": int(user_score // 10) if user_score > 0 else 1,
                "mcp_flow_status": "completed_successfully",
                "tools_called": ", ".join(tools_used),
                "data_processed": True,
                "suggestion_saved": save_success
            }
            
        except Exception as e:
            logger.error(f"‚ùå CRITICAL ERROR in MCP Flow: {e}")
            return {
                "success": False,
                "error": str(e),
                "mcp_flow_status": "critical_error"
            }

# Global MCP Client instance
mcp_client = MCPClient()

# =============================================================================
# üîÑ MCP ENDPOINTS - Frontend Interface
# =============================================================================

@router.post("/daily-suggestion", response_model=MCPResponse)
async def get_daily_suggestion(
    request: MCPRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    üéØ ANA MCP ENDPOINT 
    
    Frontend sadece user_id g√∂nderir
    MCP Protocol ile t√ºm akƒ±≈ü otomatik √ßalƒ±≈üƒ±r
    
    Flow: Frontend ‚Üí MCP Host ‚Üí Gemini AI ‚Üí MCP Server ‚Üí Database ‚Üí Frontend
    """
    try:
        print(f"üå≥ FinTree MCP Request: {request.user_id}")
        
        # MCP Protocol Full Flow
        mcp_result = await mcp_client.process_mcp_request(user_id=request.user_id)
        
        if mcp_result.get("success"):
            return MCPResponse(
                success=True,
                suggestion_text=mcp_result.get("suggestion_text"),
                user_score=mcp_result.get("user_score"),
                tree_level=int(mcp_result.get("user_score", 0) // 10) if mcp_result.get("user_score") else 1,
                mcp_flow_status=mcp_result.get("mcp_flow_status", "completed")
            )
        else:
            return MCPResponse(
                success=False,
                error=mcp_result.get("error", "Unknown MCP error"),
                mcp_flow_status="error"
            )
            
    except Exception as e:
        print(f"‚ùå MCP Endpoint Error: {e}")
        return MCPResponse(
            success=False,
            error=str(e),
            mcp_flow_status="endpoint_error"
        )

 