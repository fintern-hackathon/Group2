#!/usr/bin/env python3
"""
üîÑ MCP Client Router
Frontend ‚Üí MCP Host ‚Üí Gemini AI ‚Üí MCP Server ‚Üí Database
"""

from fastapi import APIRouter, HTTPException, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel
from typing import Optional, Dict, Any
import google.generativeai as genai
from google.generativeai.types import FunctionDeclaration
import requests
import os
from datetime import datetime
import time
import logging
import json

from app.database.connection import get_db
from app.mcp_server import mcp_server  # Internal call i√ßin ekle
from app.services.personality_service import PersonalityService

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Router setup
router = APIRouter()

# Request/Response Models
class MCPRequest(BaseModel):
    user_id: str

class MCPResponse(BaseModel):
    success: bool
    suggestion_text: Optional[str] = None
    suggestion: Optional[str] = None  # Frontend compatibility
    suggestion_id: Optional[str] = None
    user_score: Optional[float] = None
    tree_level: Optional[int] = None
    mcp_flow_status: str
    error: Optional[str] = None

# MCP Configuration
MCP_BASE_URL = "http://192.168.1.16:8006/api/v1/mcp"
GEMINI_API_KEY = "AIzaSyA5uWgtk7rejkcY5FFXITOweB_zRhJaxEY"

# Gemini AI Function Definitions (DOƒûRU FORMAT)
def create_mcp_functions():
    """Gemini AI i√ßin doƒüru formatta function definitions olu≈ütur"""
    return [
        FunctionDeclaration(
            name="get_user_financial_data",
            description="Kullanƒ±cƒ±nƒ±n tam finansal verilerini al (skor, gelir, gider, kategori daƒüƒ±lƒ±mƒ±)",
            parameters={
                "type": "OBJECT",
                "properties": {
                    "user_id": {
                        "type": "STRING", 
                        "description": "Kullanƒ±cƒ±nƒ±n UUID'si"
                    }
                },
                "required": ["user_id"]
            }
        ),
        FunctionDeclaration(
            name="get_user_score",
            description="Kullanƒ±cƒ±nƒ±n mevcut finansal skorunu ve aƒüa√ß seviyesini al",
            parameters={
                "type": "OBJECT",
                "properties": {
                    "user_id": {
                        "type": "STRING", 
                        "description": "Kullanƒ±cƒ±nƒ±n UUID'si"
                    }
                },
                "required": ["user_id"]
            }
        ),
        FunctionDeclaration(
            name="get_recent_transactions", 
            description="Kullanƒ±cƒ±nƒ±n son i≈ülemlerini ve harcama trendlerini al",
            parameters={
                "type": "OBJECT",
                "properties": {
                    "user_id": {
                        "type": "STRING", 
                        "description": "Kullanƒ±cƒ±nƒ±n UUID'si"
                    },
                    "days": {
                        "type": "INTEGER",
                        "description": "Ka√ß g√ºnl√ºk ge√ßmi≈üe bakƒ±lacak"
                    }
                },
                "required": ["user_id"]
            }
        ),
        FunctionDeclaration(
            name="get_spending_analysis",
            description="Detaylƒ± harcama analizi ve kategori y√ºzdeleri", 
            parameters={
                "type": "OBJECT",
                "properties": {
                    "user_id": {
                        "type": "STRING",
                        "description": "Kullanƒ±cƒ±nƒ±n UUID'si"
                    }
                },
                "required": ["user_id"]
            }
        ),
        FunctionDeclaration(
            name="save_ai_suggestion",
            description="AI tarafƒ±ndan √ºretilen finansal √∂neriyi database'e kaydet",
            parameters={
                "type": "OBJECT", 
                "properties": {
                    "user_id": {
                        "type": "STRING",
                        "description": "Kullanƒ±cƒ±nƒ±n UUID'si"
                    },
                    "suggestion_text": {
                        "type": "STRING",
                        "description": "AI'nƒ±n √ºrettiƒüi √∂neri metni"
                    },
                    "user_score_at_time": {
                        "type": "NUMBER",
                        "description": "√ñneri anƒ±ndaki kullanƒ±cƒ± skoru"
                    }
                },
                "required": ["user_id", "suggestion_text"]
            }
        )
    ]

# MCP Functions instance
MCP_FUNCTIONS = create_mcp_functions()

class MCPClient:
    """MCP Protocol Client - Gemini AI ile MCP Server arasƒ±nda k√∂pr√º"""
    
    def __init__(self):
        # Gemini AI Configuration
        genai.configure(api_key=GEMINI_API_KEY)
        self.model = genai.GenerativeModel(
            'gemini-1.5-flash',  # Stable model - proven to work
            tools=MCP_FUNCTIONS
        )
        
        # System Prompt for FinTree
        self.system_prompt = """
        üå≥ FinTree Finansal Danƒ±≈üman Asistanƒ±sƒ±n!
        
        MCP PROTOCOL: 
        PHASE 1: Hangi verilere ihtiyacƒ±n var? MCP tool'larƒ± √ßaƒüƒ±r!
        PHASE 2: Verileri topla ve analiz et
        PHASE 3: Anlamlƒ± finansal √∂neri √ºret
        
        AVAILABLE MCP TOOLS:
        1. get_user_financial_data - Tam finansal durum (skor, gelir, gider, kategori daƒüƒ±lƒ±mƒ±)
        2. get_user_score - Sadece skor ve aƒüa√ß seviyesi  
        3. get_recent_transactions - Son harcamalar ve trendler
        4. get_spending_analysis - Detaylƒ± harcama analizi ve y√ºzdeler
        
        STRATEGY:
        - ƒ∞LK √∂nce get_user_financial_data veya get_user_score √ßaƒüƒ±r
        - Sonra get_recent_transactions veya get_spending_analysis √ßaƒüƒ±r
        - Verileri analiz edip DETAYLI √∂neri √ºret
        
        √ñNERƒ∞ KRƒ∞TERLERƒ∞:
        üìä Skor analizi (0-100 arasƒ±)
        üå≥ Aƒüa√ß seviyesi motivasyonu (1-10 seviye)
        üí∞ Kategorilere √∂zel tavsiyeler (food, transport, bills, entertainment, health, clothing)
        üìà Trend analizi (y√ºkseli≈ü/d√º≈ü√º≈ü)
        üéØ Kƒ±sa/orta/uzun vadeli hedefler
        üí° Actionable, spesifik adƒ±mlar
        
        KONU≈ûMA STƒ∞Lƒ∞:
        - T√ºrk√ße ve samimi
        - Aƒüa√ß metaforlarƒ± kullan üå≥üåøüå±üçÉ
        - Motivasyonel ama ger√ßek√ßi
        - Sayƒ±sal verilerle destekle
        - Emoji kullan ama abartma
        """

    async def call_mcp_tool(self, tool_name: str, db: AsyncSession, **kwargs) -> Dict[str, Any]:
        """MCP Server'a tool √ßaƒürƒ±sƒ± yap (internal call)"""
        try:
            # Internal call mapping
            if tool_name == "get_user_score":
                result = await mcp_server.get_user_score(db, kwargs.get("user_id"))
            elif tool_name == "get_user_financial_data":
                result = await mcp_server.get_user_financial_data(db, kwargs.get("user_id"))
            elif tool_name == "get_recent_transactions":
                result = await mcp_server.get_recent_transactions(db, kwargs.get("user_id"), kwargs.get("days", 30))
            elif tool_name == "get_spending_analysis":
                result = await mcp_server.get_spending_analysis(db, kwargs.get("user_id"), kwargs.get("days", 30))
            elif tool_name == "save_ai_suggestion":
                from app.mcp_server import MCPSuggestionSave
                suggestion_data = MCPSuggestionSave(
                    user_id=kwargs.get("user_id"),
                    suggestion_text=kwargs.get("suggestion_text"),
                    user_score_at_time=kwargs.get("user_score_at_time")
                )
                result = await mcp_server.save_ai_suggestion(db, suggestion_data)
            else:
                return {"success": False, "error": f"Tool {tool_name} not implemented"}
            # MCPToolResponse tipinde d√∂ner, dict'e √ßevir
            return result.dict() if hasattr(result, 'dict') else dict(result)
        except Exception as e:
            return {"success": False, "error": str(e)}

    async def process_mcp_request(self, user_id: str, db: AsyncSession) -> Dict[str, Any]:
        """
        MCP Protocol Ana Akƒ±≈üƒ± - FIXED VERSION
        AI √ßalƒ±≈ümazsa HATA d√∂ner, fake response YOK!
        """
        logger.info(f"üöÄ STEP 1: MCP Flow Started for User: {user_id}")
        
        try:
            # Otomatik prompt olu≈ütur
            auto_query = "G√ºnl√ºk finansal durumumu analiz et ve ki≈üiselle≈ütirilmi≈ü √∂neriler ver."
            full_message = f"{self.system_prompt}\n\nKullanƒ±cƒ± ID: {user_id}\nƒ∞stek: {auto_query}"
            
            logger.info(f"üìù STEP 2: Auto Query Generated: {auto_query}")
            
            # STEP 2.5: Personality verisini √ßek
            personality_service = PersonalityService()
            personality_result = await personality_service.get_user_personality(db, user_id)
            personality_block = ""
            if personality_result.get('success') and personality_result['data']:
                pdata = personality_result['data']
                personality_block = f"""
=== KULLANICI Kƒ∞≈ûƒ∞Lƒ∞K PROFƒ∞Lƒ∞ ===\n{pdata.get('personality_name', '')} (G√ºven: {pdata.get('confidence_score', 0):.2f})\nA√ßƒ±klama: {pdata.get('description', '')}\n"""
                # AI context varsa ekle
                if pdata.get('ai_context'):
                    personality_block += f"{pdata['ai_context']}\n"
                # √ñne √ßƒ±kan traitleri ekle (isteƒüe baƒülƒ±)
                traits = pdata.get('traits', {})
                if traits:
                    # traits_json: personality tiplerine g√∂re AI'nƒ±n kullandƒ±ƒüƒ± skorlar ve √∂ne √ßƒ±kan √∂zelliklerdir.
                    personality_block += "A≈üaƒüƒ±da kullanƒ±cƒ±nƒ±n ki≈üilik analizine g√∂re √∂ne √ßƒ±kan trait skorlarƒ± (0-1 arasƒ±) yer almaktadƒ±r.\n"
                    trait_lines = []
                    for t_name, t_val in traits.items():
                        if isinstance(t_val, dict) and 'total_score' in t_val:
                            score = t_val['total_score']
                            trait_lines.append(f"- {t_val.get('name', t_name)}: {score:.2f}")
                        elif isinstance(t_val, (float, int)):
                            trait_lines.append(f"- {t_name}: {t_val:.2f}")
                    if trait_lines:
                        personality_block += "\n".join(trait_lines) + "\n"
                    personality_block += "Bilge Bayku≈ü tipi kullanƒ±cƒ±, planlƒ± hareket eder, uzun vadeli d√º≈ü√ºn√ºr. Harcamalarƒ±nda genellikle d√ºzenli bir tasarruf modeli izler, riskten ka√ßar ve genellikle faturalar ile gƒ±da gibi temel ihtiya√ßlara odaklanƒ±r.Me≈ügul Sincap tipi kullanƒ±cƒ±, a≈üƒ±rƒ± derecede tasarruf yapar ancak keyif almayƒ± ihmal eder. Gelirinin %40‚Äôƒ±ndan fazlasƒ±nƒ± biriktirir ve eƒülence ya da giyim gibi alanlara √ßok az harcama yapar.√ñzg√ºr Kelebek tipi kullanƒ±cƒ±, anlƒ±k kararlar alƒ±r, spontane ya≈üar ve hayatƒ±n tadƒ±nƒ± √ßƒ±karmayƒ± sever. Eƒülence harcamalarƒ± y√ºksektir ve harcama davranƒ±≈ülarƒ± deƒüi≈ükendir.Sabit Kaplumbaƒüa tipi kullanƒ±cƒ±, d√ºzenli ve tutarlƒ±dƒ±r. Harcama kalƒ±plarƒ±nda √ßok az deƒüi≈ükenlik g√∂r√ºl√ºr ve genellikle aynƒ± miktarlarda harcama yapar. Deƒüi≈üikliklerden ho≈ülanmaz.Cesur Aslan tipi kullanƒ±cƒ±, risk almayƒ± sever, b√ºy√ºk harcamalar yapar ve finansal hedeflere odaklanƒ±r. Harcamalarƒ±nda b√ºy√ºk dalgalanmalar olabilir.Konfor Koala tipi kullanƒ±cƒ±, ya≈üam kalitesine √∂nem verir ve rahatlƒ±ƒüƒ± √∂n planda tutar. Gƒ±da, saƒülƒ±k ve eƒülence gibi alanlarda y√ºksek harcama eƒüilimindedir.Bu trait skorlarƒ±, kullanƒ±cƒ±nƒ±n harcama alƒ±≈ükanlƒ±klarƒ±ndan √ßƒ±karƒ±lan ki≈üilik √∂zelliklerini ve finansal davranƒ±≈ülarƒ±nƒ± yansƒ±tƒ±r.\n"
            else:
                personality_block = ""

            logger.info(f"üîß STEP 3: Personality Block: {personality_block}")
            # STEP 3: Veri toplama (AI olmadan)
            logger.info("üîß STEP 3: Collecting user data from MCP tools...")
            
            collected_data = {}
            tools_used = []
            
            # Akƒ±llƒ± veri toplama - Son 30 g√ºn odaklƒ±
            data_collection_tools = [
                ("get_user_score", {}),  # Mevcut skor
                ("get_recent_transactions", {"days": 30}),  # Son 1 ay i≈ülemler
                ("get_spending_analysis", {"days": 30})  # Son 1 ay analiz
            ]
            
            for tool_name, params in data_collection_tools:
                try:
                    logger.info(f"üîß Calling {tool_name}...")
                    result = await self.call_mcp_tool(tool_name, db, user_id=user_id, **params)
                    
                    if result.get('success'):
                        collected_data[tool_name] = result.get('data', {})
                        tools_used.append(tool_name)
                        logger.info(f"‚úÖ {tool_name}: SUCCESS")
                    else:
                        logger.warning(f"‚ö†Ô∏è {tool_name}: FAILED - {result.get('error', 'Unknown')}")
                        
                except Exception as e:
                    logger.error(f"‚ùå {tool_name}: ERROR - {e}")
            
            logger.info(f"üìä STEP 4: Data collection complete. Tools used: {tools_used}")
            
            if not collected_data:
                logger.error("‚ùå STEP 4: No data collected from any tool!")
                return {
                    "success": False,
                    "error": "Veri toplama ba≈üarƒ±sƒ±z. Database baƒülantƒ±sƒ± kontrol edin.",
                    "mcp_flow_status": "data_collection_failed"
                }
            
            # STEP 5: AI'ya veri ve prompt g√∂nder (SINGLED REQUEST)
            logger.info("ü§ñ STEP 5: Sending data to Gemini AI...")
            
            # MOBƒ∞L BANKACILIK UYGULAMASI PROMPT
            enhanced_prompt = f"""
            Sen FinTree mobil bankacƒ±lƒ±k uygulamasƒ±nƒ±n AI asistanƒ±sƒ±n. üì±üå≥

=== KULLANICI Kƒ∞≈ûƒ∞Lƒ∞K PROFƒ∞Lƒ∞ ===
{personality_block}

=== VERƒ∞ ANALƒ∞Zƒ∞ (Son 30 g√ºn odaklƒ±) ===
{json.dumps(collected_data, indent=2, ensure_ascii=False)}

=== YAZIM KURALLARI ===
‚úÖ Doƒürudan kullanƒ±cƒ±ya hitap et ("Sen", "Siz")
‚úÖ FinTree uygulamasƒ±ndan bahset
‚úÖ Kƒ±sa ve √∂z (20-30 kelime ideal). 30 kelimeyi asla a≈ümasƒ±n.
‚úÖ Mobil ekranda rahat okunabilir
‚úÖ Motivasyonel ve pozitif ton
‚úÖ Spesifik sayƒ±sal √∂neriler ver
‚úÖ Eylem odaklƒ± tavsiyelerde bulun
‚ùå Personality isimleriyle (Cesur Aslan, Bilge Bayku≈ü gibi) veya ba≈üka bir hitap ≈üekliyle asla hitap etme
‚ùå Harcamalarƒ± artƒ±rmaya te≈üvik eden √∂neriler verme
‚ùå Merhaba gibi ifadeleri kullanma

=== √áIKTI FORMATI ===
Sadece √∂neri metnini yaz. Ba≈ülƒ±k, a√ßƒ±klama vs. yok.
√ñrnek: "Bu ay kahve harcaman %15 arttƒ±! ‚òï G√ºnde 2 kahve yerine 1 i√ßersen aylƒ±k 180‚Ç∫ tasarruf edebilirsin. üí∞"

=== √ñZEL TALƒ∞MATLAR ===
Kullanƒ±cƒ±nƒ±n ger√ßek finansal verilerine ve ki≈üilik profiline g√∂re ki≈üisel, spesifik ve uygulanabilir √∂neriler ver! üéØ
"Son 30 g√ºn", "merhaba" veya ki≈üilik isimleriyle (cesur aslan gibi) hitaplarda bulunma √ß√ºnk√º bu bir g√ºnl√ºk tavsiye alanƒ±dƒ±r.
Harcamalarƒ± azaltmaya, tasarruf saƒülamaya ya da mevcut b√ºt√ßeyi daha verimli kullanmaya y√∂nelik pozitif √∂neriler sun. ‚ú® """
            logger.info(f"üîß STEP 6: Enhanced Prompt: {enhanced_prompt}")
            try:
                logger.info("‚è≥ STEP 6: Rate limiting...")
                time.sleep(2)
                
                # TEK REQUEST - Function calling YOK
                logger.info("ü§ñ STEP 7: Calling Gemini AI (single request)...")
                ai_response = self.model.generate_content(enhanced_prompt)
                
                if ai_response and ai_response.text:
                    suggestion_text = ai_response.text.strip()
                    logger.info(f"‚úÖ STEP 7: AI Response received ({len(suggestion_text)} chars)")
                    logger.info(f"üìù Preview: {suggestion_text[:100]}...")
                else:
                    logger.error("‚ùå STEP 7: AI returned empty response")
                    return {
                        "success": False,
                        "error": "AI bo≈ü response d√∂nd√º",
                        "mcp_flow_status": "ai_empty_response"
                    }
                
            except Exception as ai_error:
                logger.error(f"‚ùå STEP 7: Gemini AI Error: {ai_error}")
                
                # Quota check
                if "429" in str(ai_error) or "quota" in str(ai_error).lower():
                    return {
                        "success": False,
                        "error": "Gemini API quota a≈üƒ±ldƒ±",
                        "mcp_flow_status": "quota_exceeded"
                    }
                else:
                    return {
                        "success": False,
                        "error": f"AI hatasƒ±: {str(ai_error)}",
                        "mcp_flow_status": "ai_error"
                    }
            
            # STEP 8: √ñneriyi database'e kaydet
            logger.info("üíæ STEP 8: Saving suggestion to database...")
            
            user_score = 0
            if 'get_user_score' in collected_data:
                user_score = collected_data['get_user_score'].get('score', 0)
            
            try:
                save_result = await self.call_mcp_tool(
                    "save_ai_suggestion",
                    db,
                    user_id=user_id,
                    suggestion_text=suggestion_text[:1000],
                    user_score_at_time=user_score
                )
                
                save_success = save_result.get('success', False)
                logger.info(f"üíæ STEP 8: Save result: {save_success}")
                
            except Exception as save_error:
                logger.error(f"‚ùå STEP 8: Save error: {save_error}")
                save_success = False
            
            # STEP 9: Final response
            logger.info("üéâ STEP 9: MCP Flow completed successfully!")
            
            return {
                "success": True,
                "suggestion_text": suggestion_text,
                "user_score": user_score,
                "tree_level": int(user_score // 10) if user_score > 0 else 1,
                "mcp_flow_status": "completed_successfully",
                "tools_called": ", ".join(tools_used),
                "data_processed": True,
                "suggestion_saved": save_success
            }
            
        except Exception as e:
            logger.error(f"‚ùå CRITICAL ERROR in MCP Flow: {e}")
            return {
                "success": False,
                "error": str(e),
                "mcp_flow_status": "critical_error"
            }

# Global MCP Client instance
mcp_client = MCPClient()

# =============================================================================
# üîÑ MCP ENDPOINTS - Frontend Interface
# =============================================================================

@router.post("/daily-suggestion", response_model=MCPResponse)
async def get_daily_suggestion(
    request: MCPRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    üéØ ANA MCP ENDPOINT 
    
    Frontend sadece user_id g√∂nderir
    MCP Protocol ile t√ºm akƒ±≈ü otomatik √ßalƒ±≈üƒ±r
    
    Flow: Frontend ‚Üí MCP Host ‚Üí Gemini AI ‚Üí MCP Server ‚Üí Database ‚Üí Frontend
    """
    try:
        print(f"üå≥ FinTree MCP Request: {request.user_id}")
        
        # MCP Protocol Full Flow
        mcp_result = await mcp_client.process_mcp_request(user_id=request.user_id, db=db)
        
        if mcp_result.get("success"):
            suggestion_text = mcp_result.get("suggestion_text")
            return MCPResponse(
                success=True,
                suggestion_text=suggestion_text,
                suggestion=suggestion_text,  # Frontend compatibility
                user_score=mcp_result.get("user_score"),
                tree_level=int(mcp_result.get("user_score", 0) // 10) if mcp_result.get("user_score") else 1,
                mcp_flow_status=mcp_result.get("mcp_flow_status", "completed")
            )
        else:
            return MCPResponse(
                success=False,
                error=mcp_result.get("error", "Unknown MCP error"),
                mcp_flow_status="error"
            )
            
    except Exception as e:
        print(f"‚ùå MCP Endpoint Error: {e}")
        return MCPResponse(
            success=False,
            error=str(e),
            mcp_flow_status="endpoint_error"
        )

 